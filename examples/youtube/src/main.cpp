#include <opencv2/imgcodecs.hpp>
#include <opencv2/imgproc.hpp>
#include <opencv2/videoio.hpp>
#include <opencv2/highgui.hpp>
#include <opencv2/video.hpp>
#include <cstdio>
#include <iostream>
#include <stdexcept>
#include <string>
#include "api/client.h"
#include "api/response.h"
#include "api/environment.h"
#include "processors/track.h"
#include "processors/track-collector.h"
#include "processors/object-stream.h"
#include "util/time.h"
#include <chrono>

using namespace cv;

//Motion detection parameters
const int           MIN_AREA = 3000;
const int           KERNEL_SIZE = 7;
const int           dilation_size = 5;
const int           resize_to_height = 480;
const double        SIGMA = 4.5;

//
const int           FLIPBOOK_FPS = 1;
const Size          FLIPBOOK_SIZE = Size(480,360);
const int           FLIPBOOK_UPDATE_S = 60;
const char*         FLIPBOOK_TMP_FILE = "flip.mp4";
const int           BACKGROUND_UPDATE_MIN = 1;
const char*         BACKGROUND_TMP_FILE = "back.jpg";
const char*         BLOB_TMP_FILE = "blob.jpg";
const int           EVENT_UPDATE_MIN = 1;

prism::connect::api::Client client{prism::connect::api::environment::ApiRoot(),
	                                       prism::connect::api::environment::ApiToken()};
std::unique_ptr<prism::connect::api::Instrument> this_camera;
std::unique_ptr<VideoWriter> writer;
std::unique_ptr<prism::connect::processors::Track>  track;


Rect resizeRect(Rect r,float scale)
{
    return Rect(r.x*scale,r.y*scale,r.width*scale,r.height*scale);
}

class Event{
public:
	void AddTimestamp(const std::chrono::system_clock::time_point& timestamp)
	{
		nlohmann::json record;
		record["timestamp"] = prism::connect::util::IsoTime(timestamp);
		data_.push_back(record);
	}

	nlohmann::json ToJson(){
		return data_;
	}
private:
	nlohmann::json data_;
};

std::unique_ptr<Event>  event;

void initPrismService(std::string camera_name)
{
	auto accounts = client.QueryAccounts();

	std::cout<<"API Endpoint"<<prism::connect::api::environment::ApiRoot()<<std::endl;
    for (const auto& account : accounts)
    {
        std::cout << "Account[" << account.id_ << "]:" << std::endl;
        std::cout << "Name: " << account.name_ << std::endl;
        std::cout << "Url: " << account.url_ << std::endl;
        std::cout << "Instruments Url: " << account.instruments_url_ << std::endl;
        std::cout << std::endl;

        // Get the list of Instruments belonging to an Account
        std::vector<prism::connect::api::Instrument> instruments = client.QueryInstruments(account);

        //Find our camera by name
        bool found = false;
        for(auto& instrument : instruments)
        {
            if(instrument.name_ == camera_name)
            {
                found = true;
                this_camera.reset(new prism::connect::api::Instrument(instrument));
            }
            else
                std::cout << "Camera: " << instrument.name_ << std::endl;
        }

        //If camera does not exist - create it
        if(!found)
        {
            this_camera.reset(new prism::connect::api::Instrument());
            this_camera->name_ = camera_name;
            this_camera->instrument_type_ = "camera";

            // Register an unregistered Instrument to an Account
            prism::connect::api::Response result = client.RegisterInstrument(account, *this_camera.get());
            std::cerr << "Camera registration status " << result.status_code
                      << " {" << result.text << "}" << std::endl;
        }
        std::cout << "Instrument[" << this_camera->name_ << "]:" << std::endl;

        break;
	}
}


int main(int argc, char** argv)
{
    if (argc < 3) {
        std::cout << "Usage:\n\tyt_camera <camera-name> <input-file>\n" << std::endl;
        return -1;
    }

    std::cout << "app name: " << argv[0] << std::endl;
    std::cout << "camera name: " << argv[1] << std::endl;
    std::cout << "input file: " << argv[2] << std::endl;

    std::string cmd, stream_id, stream_URL, FormatCode;
    std::vector<int> compression_params;
    compression_params.push_back(CV_IMWRITE_JPEG_QUALITY);
    compression_params.push_back(95);

    if(argc < 2 ||argc >3 )
    {
        std::cout<<"Usage "<< argv[0]<< " CAMERA_NAME [VIDEO_FILE_PATH]"<<std::endl;
        return 0;
    }

    char* camera_name = argv[1];
    //Init connect service
    initPrismService(camera_name);

    //If no processing stream specified - just create device
    if(argc == 2)
        return 0;

    //Open video stream
    char* fname = argv[2];
    std::cerr<<fname;
    VideoCapture cap(fname);
    if(!cap.isOpened()) // check if we succeeded
        return -1;
    int fps = cap.get(CV_CAP_PROP_FPS);

    std::cout << "Processing..." << std::endl;

    // create Background Subtractor objects

    Mat fgMaskMOG2; // fg mask fg mask generated by MOG2 method
    Ptr<BackgroundSubtractor> pMOG2; // MOG2 Background subtractor
    pMOG2 = createBackgroundSubtractorMOG2(); // MOG2 approach

    Mat firstFrame;
    int fnum = 0;
    std::chrono::system_clock::time_point ftime;
    int last_fnum = -10000;
    int saved_frames = 0;
    std::chrono::system_clock::time_point flipbook_start_time;
    bool motion = false;
    bool was_motion = false;
    std::chrono::system_clock::time_point  last_b_update_time;
    std::chrono::system_clock::time_point  last_event_update_time;
    std::chrono::system_clock::time_point  motion_start;
    int blob_id = 0;
    int last_blob_fnum = -10000;


    //Set current timepoint to 1h ago since we processing faster than real time
    //and will be posting to future
    ftime = std::chrono::system_clock::now() - std::chrono::hours(1);

    int prevMinute = -1;

    for(;;)
    {
        Mat frame, gray_frame;

        cap >> frame; // get a new frame from camera
        //get frame timestamp
        ftime += std::chrono::milliseconds(1000 / fps);

        if (frame.empty())
        {
            break;
        }

        cvtColor(frame, gray_frame, COLOR_BGR2GRAY); //switch to grayscale

        float scale =(float) resize_to_height/gray_frame.rows;
        int resized_width = gray_frame.cols*scale;
        resize(gray_frame, gray_frame, Size(resized_width,resize_to_height), 0, 0, CV_INTER_CUBIC); // resize

        GaussianBlur(gray_frame, gray_frame, Size(KERNEL_SIZE,KERNEL_SIZE), SIGMA, SIGMA);
        pMOG2->apply(gray_frame, fgMaskMOG2);

        Mat dilated;
        Mat element = getStructuringElement( MORPH_ELLIPSE,
                                            Size( 2*dilation_size + 1, 2*dilation_size+1 ),
                                            Point( dilation_size, dilation_size ) );
        dilate(fgMaskMOG2,dilated,element); // dilate the thresholded image to fill in holes, then find contours on thresholded image

        std::vector<std::vector<Point> > contours;
        std::vector<Vec4i> hierarchy;
        findContours( dilated, contours, hierarchy, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE, Point(0, 0) ); //find contours

        motion = false;
        for( int i = 0; i< contours.size(); i++ ) // loop over the contours
        {
            double area = contourArea(contours[i]);
            if(area < MIN_AREA)
                continue;

            motion = true;
            CvRect r = boundingRect(contours[i]);
            r = resizeRect(r,1.0/scale);

            //Mark motion on frame
            Scalar color = Scalar(255, 0,0 );
            rectangle( frame, r,color);

            if (fnum - last_blob_fnum > fps/FLIPBOOK_FPS)
            {
                //Add motion blob to object stream
                Mat blob = Mat(frame, r);
                imwrite(BLOB_TMP_FILE,blob,compression_params);
                prism::connect::processors::ObjectStream object_s(blob_id,ftime,r.x,r.y,r.width,r.height,frame.cols,frame.rows);
                std::cerr<<"Posting object stream"<<std::endl;
                prism::connect::api::Response result = client.PostImageFileObjectStream(*this_camera.get(),object_s.ToJson(),BLOB_TMP_FILE);
                std::cerr<<" status"<<result.status_code<<" {"<<result.text<<"}"<<std::endl;
                last_blob_fnum = fnum;
            }

        }

        //Update blob id when motion ended
        if(!motion && was_motion)
            blob_id++;

        //Update flipbook
        int currentMinute = std::chrono::duration_cast<std::chrono::minutes>(ftime.time_since_epoch()).count();
        if (prevMinute < 0)
            prevMinute = currentMinute;

        bool needUpdateData = prevMinute < currentMinute;

        if (needUpdateData)
        {
            prism::connect::api::Response result;

            long long totalMs = std::chrono::duration_cast<std::chrono::milliseconds>(ftime.time_since_epoch()).count();
            long long currMinMs = totalMs % 60000LL;

            std::cout << "totalMs: " << totalMs << std::endl;
            std::cout << "currMinMs: " << currMinMs << std::endl;

            std::chrono::system_clock::time_point currentMinuteStart = ftime - std::chrono::milliseconds(currMinMs);
            std::chrono::system_clock::time_point prevMinuteStart = currentMinuteStart - std::chrono::minutes(1);
            std::chrono::system_clock::time_point prevMinuteEnd = prevMinuteStart + std::chrono::seconds(59);

            {
                std::time_t ttp = std::chrono::system_clock::to_time_t(ftime);
                std::cout << "ftime: " << std::ctime(&ttp);
            }

            {
                std::time_t ttp = std::chrono::system_clock::to_time_t(currentMinuteStart);
                std::cout << "currentMinuteStart: " << std::ctime(&ttp);
            }

            {
                std::time_t ttp = std::chrono::system_clock::to_time_t(prevMinuteStart);
                std::cout << "prevMinuteStart: " << std::ctime(&ttp);
            }

            {
                std::time_t ttp = std::chrono::system_clock::to_time_t(prevMinuteEnd);
                std::cout << "prevMinuteEnd: " << std::ctime(&ttp);
            }

            // Update Flipbook Data
            if (writer.get())
            {
                // Finalize stream, upload data
                std::cout << "Close file:" << FLIPBOOK_TMP_FILE << std::endl;
                writer->release();
                last_fnum = -1;
                // Post flipbook
                std::cerr << "Posting flipbook file " << FLIPBOOK_TMP_FILE << std::endl;
                result = client.PostVideoFileFlipbook(*this_camera.get(), prevMinuteStart,
                                                      currentMinuteStart, FLIPBOOK_SIZE.width, FLIPBOOK_SIZE.height, saved_frames, FLIPBOOK_TMP_FILE);

                std::cerr << " status" << result.status_code << " {" << result.text << "}" << std::endl;
            }

            // Update backgroud
            {
                Mat background;
                pMOG2->getBackgroundImage(background);
                imwrite(BACKGROUND_TMP_FILE, frame, compression_params); // save image
                std::cerr << "Posting background file " << BACKGROUND_TMP_FILE << std::endl;
                result = client.PostImageFile(*this_camera.get(), "BACKGROUND", prevMinuteStart, prevMinuteStart, BACKGROUND_TMP_FILE);
                std::cerr << " status" << result.status_code << " {" << result.text << "}" << std::endl;
                last_b_update_time = ftime;
            }

            // Update Event
            {
                // Start event
                event.reset(new Event());
                // Write event timestamp
                std::chrono::system_clock::time_point rounded_to_min = std::chrono::time_point_cast<std::chrono::minutes>(ftime);
                event->AddTimestamp(rounded_to_min);
                // Post Event
                std::cerr << "Posting event" << std::endl;
                result = client.PostTimeSeriesEvents(*this_camera.get(), prevMinuteEnd, event->ToJson());
                std::cerr << " status" << result.status_code << " {" << result.text << "}" << std::endl;
            }
        }

        // Update flipbook video file
        if (!writer.get() || needUpdateData)
        {
            // Remove old file
            std::remove(FLIPBOOK_TMP_FILE);
            // Open video file
            std::cout << "Open file:" << FLIPBOOK_TMP_FILE << std::endl;
            writer.reset(new VideoWriter(FLIPBOOK_TMP_FILE, VideoWriter::fourcc('H','2','6','4'), FLIPBOOK_FPS, FLIPBOOK_SIZE, true));
            saved_frames = 0;
            flipbook_start_time = ftime;
        }

        // Write frames with given FPS to flipbook video file
        if (writer.get() && fnum - last_fnum >= fps/FLIPBOOK_FPS)
        {
            // Write frame
            std::cout << "Write flipbook video frame" << std::endl;
            Mat flip_frame;
            resize(frame, flip_frame, FLIPBOOK_SIZE, 0, 0, CV_INTER_CUBIC);
            writer->write(flip_frame);
            saved_frames++;
            last_fnum = fnum;
        }

        prevMinute = currentMinute;

        fnum++;
        was_motion = motion;
    }

    // the camera will be deinitialized automatically in VideoCapture destructor
    return 0;
}
